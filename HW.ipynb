{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787b73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import tiktoken\n",
    "import random\n",
    "from model import GPTConfig, GPT\n",
    "import time\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a361b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f039e74f550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed so we get the same results\n",
    "\n",
    "seed = 2845\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee72b2",
   "metadata": {},
   "source": [
    "First, we need read the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3c6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('poetry.csv', newline='') as csvfile:\n",
    "    raw_data = list(csv.reader(csvfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c46c73",
   "metadata": {},
   "source": [
    "Then, we process it into a form that our GPT model can use. This is where we have to design our prompt and use soft prompting. Fill in the function `process_poem` to return a prompt based on the information we have about the poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99b2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_poem(author, name, age, poem_type):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        author: str\n",
    "            The author of the poem\n",
    "        name: str\n",
    "            The name of the poem\n",
    "        age: str\n",
    "            The \"age\" that the poem is from (either \"Renaissance\" or \"Modern\")\n",
    "                Note: each poem author will either be in the Renaissance\n",
    "                      or Modern age, meaning that this is redundant information\n",
    "        poem_type: str\n",
    "            The type of poem, will be one of these: \"Love\", \"Mythology & Folklore\", \"Nature\"\n",
    "    \n",
    "    Returns:\n",
    "        prompt: str\n",
    "            The prompt that we use for soft prompting\n",
    "    \"\"\"\n",
    "    \n",
    "    return \"Here is a \" + age + \" \" + poem_type + \" poem written by \" + author + ' called \"' + name + '\"\\n\\n'\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "encode = lambda x: enc.encode_ordinary(x)\n",
    "\n",
    "dataset = [(encode(process_poem(author, name, age, poem_type)), \n",
    "            encode(poem_content)) \n",
    "           for author, poem_content, name, age, poem_type in raw_data[1:]]\n",
    "\n",
    "max_prompt_length = max([len(poem[0]) for poem in dataset])\n",
    "max_poem_length   = max([len(poem[1]) for poem in dataset])\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "n = len(dataset)\n",
    "train_data = dataset[:int(n*0.9)]\n",
    "val_data = dataset[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a706ce",
   "metadata": {},
   "source": [
    "Next, we need to write code to sample from our dataset and generate a batch of data for us to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e309c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: List[prompt, poem_content]\n",
    "            The dataset that we want to sample from (either training or validation)\n",
    "    Returns:\n",
    "        x: np.array[shape=(batch_size, datapoint_length)]\n",
    "        y: np.array[shape=(batch_size, datapoint_length)]\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_index = random.randrange(len(data))\n",
    "    \n",
    "    concat_data = np.array(data[sample_index][0] + data[sample_index][1])\n",
    "    \n",
    "    block_size = min(1025, len(concat_data))\n",
    "    \n",
    "    x = np.zeros(shape=(batch_size, block_size-1), dtype=np.int64)\n",
    "    y = np.zeros(shape=(batch_size, block_size-1), dtype=np.int64)\n",
    "\n",
    "    x = concat_data[:block_size-1]\n",
    "    y = concat_data[1:block_size]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e042b4",
   "metadata": {},
   "source": [
    "## Now, we train the model\n",
    "\n",
    "First things first, we set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e960b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'out'\n",
    "log_interval = 1\n",
    "eval_interval = 8\n",
    "eval_iters = 20\n",
    "\n",
    "batch_size = 64\n",
    "dropout = 0.1\n",
    "\n",
    "learning_rate = 2e-4 # max learning rate\n",
    "max_iters = 64 # total number of training iterations\n",
    "warmup_iters = 4\n",
    "lr_decay_iters = 32\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "min_lr = 2e-6\n",
    "\n",
    "grad_clip = 1.0\n",
    "device = \"cuda\"\n",
    "\n",
    "config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]\n",
    "config = {k: globals()[k] for k in config_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115dc34f",
   "metadata": {},
   "source": [
    "Then we load the GPT2-medium model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2699e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from OpenAI GPT-2 weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaharsandhaus/.conda/envs/182/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2-medium\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.1\n",
      "number of parameters: 353.77M\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initializing from OpenAI GPT-2 weights\")\n",
    "\n",
    "override_args = dict(dropout=dropout)\n",
    "model = GPT.from_pretrained(\"gpt2-medium\", override_args)\n",
    "model_args = {}\n",
    "for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n",
    "    model_args[k] = getattr(model.config, k)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=False)\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), \"cuda\")\n",
    "ctx = torch.amp.autocast(device_type=\"cuda\", dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8173516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(author, name, age, poem_type):\n",
    "    start_ids = encode(process_poem(author, name, age, poem_type))\n",
    "    x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with ctx:\n",
    "            y = model.generate(x, 256, temperature=0.8, top_k=200)\n",
    "            return enc.decode(y[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1b655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "\n",
      "My Wife is a beautiful mistress with a sweet heart, The world is indeed a beautiful place, And it has always been a beautiful place.\n",
      "\n",
      "\n",
      "'My Wife' is based on the poem the Beatles wrote to Frank Sinatra about their love relationship.\n",
      "\n",
      "\n",
      "Here is a verse about Ethel Merman from the song \"Ethel Goes to the Prom\"\n",
      "\n",
      "\n",
      "Ethel Merman on the Prom song \"Ethel Merman Goes to the Prom\"\n",
      "\n",
      "\n",
      "Ethel Merman is an attractive and lovely woman, Ethel Merman is my wife and has been my wife since I was fourteen years old.\n",
      "\n",
      "\n",
      "You see the same Ethel Merman who wore her love bracelets that day, her lady dress and her high heels. She was quite a sight to behold at her inebriated best. It was hard for me to believe that those bracelets and high heels were my own, that they were bought by my father for me, his daughter, a little girl, that I was the child of Ethel Merman and Ethel Merman only, by my mother, Ethel Merman and my father and that Ethel Merman would let anyone else have them. So many beauty bracelets and high heels!\n",
      "\n",
      "\n",
      "Some\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624f3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            the_data = train_data if split == 'train' else val_data\n",
    "            X, Y = get_batch(the_data)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# learning rate decay scheduler (cosine with warmup)\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)\n",
    "\n",
    "def get_batch(data):\n",
    "    x, y = generate_batch(data)\n",
    "    x_torch = torch.from_numpy(x).pin_memory().to(device, non_blocking=True)[None, ...]\n",
    "    y_torch = torch.from_numpy(y).pin_memory().to(device, non_blocking=True)[None, ...]\n",
    "    return x_torch, y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58be150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.1421, val loss 5.0073\n",
      "iter 0: loss 3.6166, time 5332.68ms, mfu -100.00%\n",
      "iter 1: loss 4.7811, time 4451.41ms, mfu -100.00%\n",
      "iter 2: loss 4.9809, time 4699.58ms, mfu -100.00%\n",
      "iter 3: loss 4.9199, time 4599.42ms, mfu -100.00%\n",
      "iter 4: loss 4.6358, time 5416.20ms, mfu -100.00%\n",
      "iter 5: loss 4.9782, time 5019.91ms, mfu 10.15%\n",
      "iter 6: loss 4.4182, time 4690.82ms, mfu 10.22%\n",
      "iter 7: loss 3.9940, time 4831.82ms, mfu 10.25%\n",
      "step 8: train loss 3.3427, val loss 3.3909\n",
      "saving checkpoint to out\n",
      "iter 8: loss 3.6332, time 19147.56ms, mfu 9.49%\n",
      "iter 9: loss 4.7372, time 4994.51ms, mfu 9.56%\n",
      "iter 10: loss 3.8514, time 4611.93ms, mfu 9.71%\n",
      "iter 11: loss 3.8395, time 4996.79ms, mfu 9.76%\n",
      "iter 12: loss 4.1297, time 5797.89ms, mfu 9.66%\n",
      "iter 13: loss 3.6328, time 4780.50ms, mfu 9.76%\n",
      "iter 14: loss 1.4290, time 4905.02ms, mfu 9.82%\n",
      "iter 15: loss 4.3114, time 5623.81ms, mfu 9.75%\n",
      "step 16: train loss 2.7270, val loss 2.8175\n",
      "saving checkpoint to out\n",
      "iter 16: loss 3.8459, time 19068.12ms, mfu 9.04%\n",
      "iter 17: loss 1.4224, time 5187.81ms, mfu 9.12%\n",
      "iter 18: loss 3.1396, time 4571.13ms, mfu 9.32%\n",
      "iter 19: loss 2.7642, time 5330.23ms, mfu 9.34%\n",
      "iter 20: loss 3.1749, time 5212.73ms, mfu 9.38%\n",
      "iter 21: loss 2.9597, time 5155.79ms, mfu 9.43%\n",
      "iter 22: loss 3.3036, time 4624.37ms, mfu 9.59%\n",
      "iter 23: loss 3.3714, time 5182.65ms, mfu 9.62%\n",
      "step 24: train loss 2.9120, val loss 2.9169\n",
      "iter 24: loss 3.2776, time 5300.81ms, mfu 9.61%\n",
      "iter 25: loss 3.7003, time 4399.97ms, mfu 9.81%\n",
      "iter 26: loss 3.0329, time 4294.75ms, mfu 10.02%\n",
      "iter 27: loss 2.8194, time 4792.41ms, mfu 10.08%\n",
      "iter 28: loss 4.4411, time 4265.81ms, mfu 10.26%\n",
      "iter 29: loss 3.4714, time 4920.04ms, mfu 10.27%\n",
      "iter 30: loss 2.4945, time 4676.47ms, mfu 10.33%\n",
      "iter 31: loss 3.7711, time 4813.47ms, mfu 10.36%\n",
      "step 32: train loss 2.4942, val loss 2.6723\n",
      "saving checkpoint to out\n",
      "iter 32: loss 2.7562, time 18375.98ms, mfu 9.60%\n",
      "iter 33: loss 3.6578, time 4961.81ms, mfu 9.67%\n",
      "iter 34: loss 4.0651, time 5620.41ms, mfu 9.61%\n",
      "iter 35: loss 2.9723, time 4721.86ms, mfu 9.72%\n",
      "iter 36: loss 2.5075, time 5037.87ms, mfu 9.76%\n",
      "iter 37: loss 4.5419, time 5067.40ms, mfu 9.79%\n",
      "iter 38: loss 0.3739, time 5289.92ms, mfu 9.77%\n",
      "iter 39: loss 2.3220, time 5260.11ms, mfu 9.77%\n",
      "step 40: train loss 2.8847, val loss 2.8611\n",
      "iter 40: loss 2.9482, time 5290.00ms, mfu 9.75%\n",
      "iter 41: loss 3.5527, time 4579.50ms, mfu 9.89%\n",
      "iter 42: loss 3.1789, time 4775.20ms, mfu 9.97%\n",
      "iter 43: loss 1.0033, time 4578.42ms, mfu 10.08%\n",
      "iter 44: loss 3.3924, time 4487.93ms, mfu 10.21%\n",
      "iter 45: loss 3.8740, time 4375.22ms, mfu 10.35%\n",
      "iter 46: loss 2.8892, time 4123.28ms, mfu 10.55%\n",
      "iter 47: loss 2.7940, time 5102.74ms, mfu 10.49%\n",
      "step 48: train loss 2.3627, val loss 3.1641\n",
      "iter 48: loss 3.2292, time 6148.64ms, mfu 10.27%\n",
      "iter 49: loss 2.9820, time 4214.11ms, mfu 10.45%\n",
      "iter 50: loss 0.6770, time 4201.18ms, mfu 10.62%\n",
      "iter 51: loss 2.4226, time 4419.08ms, mfu 10.71%\n",
      "iter 52: loss 4.1544, time 4474.02ms, mfu 10.78%\n",
      "iter 53: loss 3.5238, time 4837.52ms, mfu 10.75%\n",
      "iter 54: loss 2.4188, time 5031.04ms, mfu 10.69%\n",
      "iter 55: loss 3.5245, time 4676.84ms, mfu 10.71%\n",
      "step 56: train loss 2.3790, val loss 2.8749\n",
      "iter 56: loss 2.9204, time 4793.49ms, mfu 10.70%\n",
      "iter 57: loss 3.4905, time 4369.24ms, mfu 10.80%\n",
      "iter 58: loss 2.5272, time 4901.20ms, mfu 10.76%\n",
      "iter 59: loss 3.5849, time 5019.01ms, mfu 10.70%\n",
      "iter 60: loss 2.3142, time 3850.13ms, mfu 10.95%\n",
      "iter 61: loss 3.1864, time 4982.56ms, mfu 10.88%\n",
      "iter 62: loss 3.0970, time 4749.33ms, mfu 10.86%\n",
      "iter 63: loss 2.7175, time 4401.85ms, mfu 10.93%\n",
      "step 64: train loss 2.8640, val loss 2.7589\n",
      "iter 64: loss 3.2625, time 5283.30ms, mfu 10.80%\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "X, Y = get_batch(train_data)\n",
    "t0 = time.time()\n",
    "local_iter_num = 0\n",
    "running_mfu = -1.0\n",
    "\n",
    "iter_num = 0\n",
    "best_val_loss = 1e9\n",
    "\n",
    "while True:\n",
    "    # determine and set the learning rate for this iteration\n",
    "    lr = get_lr(iter_num)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    # evaluate the loss on train/val sets and write checkpoints\n",
    "    if iter_num % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        \n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            if iter_num > 0:\n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'model_args': model_args,\n",
    "                    'iter_num': iter_num,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                    'config': config,\n",
    "                }\n",
    "                print(f\"saving checkpoint to {out_dir}\")\n",
    "                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))\n",
    "\n",
    "    # forward backward update, with optional gradient accumulation to simulate larger batch size\n",
    "    # and using the GradScaler if data type is float16\n",
    "    for micro_step in range(batch_size):\n",
    "        with ctx:\n",
    "            logits, loss = model(X, Y)\n",
    "            loss = loss / batch_size # scale the loss to account for gradient accumulation\n",
    "        # immediately async prefetch next batch while model is doing the forward pass on the GPU\n",
    "        X, Y = get_batch(train_data)\n",
    "        # backward pass, with gradient scaling if training in fp16\n",
    "        scaler.scale(loss).backward()\n",
    "    # clip the gradient\n",
    "    if grad_clip != 0.0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    # step the optimizer and scaler if training in fp16\n",
    "    \n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    \n",
    "    # flush the gradients as soon as we can, no need for this memory anymore\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # timing and logging\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    t0 = t1\n",
    "    if iter_num % log_interval == 0:\n",
    "        # scale up to undo the division above, approximating the true total loss (exact would have been a sum)\n",
    "        lossf = loss.item() * batch_size\n",
    "        if local_iter_num >= 5: # let the training loop settle a bit\n",
    "            mfu = model.estimate_mfu(batch_size, dt)\n",
    "            running_mfu = mfu if running_mfu == -1.0 else 0.9*running_mfu + 0.1*mfu\n",
    "        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, mfu {running_mfu*100:.2f}%\")\n",
    "    iter_num += 1\n",
    "    local_iter_num += 1\n",
    "\n",
    "    # termination conditions\n",
    "    if iter_num > max_iters:\n",
    "        break\n",
    "    \n",
    "model.eval()\n",
    "None # to avoid printing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d238b",
   "metadata": {},
   "source": [
    "Now we sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89cf181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems, edited by Richard Houghton called \"My Wife\"\n",
      "HENRY VIII\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1497e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "HENRY VIII, KING OF ENGLAND from Collected Poems. Copyright  1923 by Helen S. Yonge. Reprinted with the permission of New Directions Publishing Corporation. Used by permission of Alfred A. Knopf, an imprint of the Knopf Doubleday Publishing Group. All rights reserved.          My Wife,                  I did long ago pray for thy love,                  To which my heart I cry,                I have long since sung with,                       To wit, that thou do so well,                On my heart, and to thee,                   On my mind, as in thy words,                    That I may have thy love\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ceab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "Hark ye, my lady, here is a true love poem written by WILLIAM SHAKESPEARE called \"As I Walk\"\n",
      "\n",
      "Who, since the earth, till it was a cedar;\r\n",
      "Which, from all the birds of earth, with every shape,\r\n",
      "Shall sing in the evening,\r\n",
      "And do the greenbird-like way.\r\n",
      "\r\n",
      "And my lady, where are you,\r\n",
      "That can tell me this?\r\n",
      "Do you, my lady, live in your couch?\r\n",
      "Come, come, do you live in your house?\r\n",
      "Do you live in a mansion or a field?\r\n",
      "Do you walk barefoot, or barefoot bare,\r\n",
      "Where you are, and where you walk?\r\n",
      "Do you live live in a house or a store?\r\n",
      "Do you live in a court or a street?\r\n",
      "Do you live in a house or a store?\r\n",
      "Do you live in a court or a street?\r\n",
      "Do you live in a court or a house?\r\n",
      "Do you live in a court or a store?\r\n",
      "Do you live in a court or a house?\r\n",
      "Do you live in a court or a store\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2068c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "HENRY VIII, KING OF ENGLAND, My Wife from Selected Poems, published by Liveright Publishing Group Australia.  Copyright  1933, 1966 by H. M. A. Liveright. Used by permission of Liveright Publishing Australia. All rights reserved.                                               Henry VIII, King of England from Selected Poems, published by Liveright Publishing Group Australia.                                     Henry VIII, King of England from Selected Poems, copyright  1986 by Liveright Publishing Australia.                                        Henry VIII, King of England from Selected Poems.                              \n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6386740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "Originally published in Poetry, May, 1787. Reprinted with the permission of Houghton Mifflin Company. Copyright  1994 by Michael Houghton Mifflin Company. Used by permission of Houghton Mifflin Company. All rights reserved. <|endoftext|>What is a Modern Nature poem written by SIR PHILIP SIDNEY called \"The Song of the Suckling Woom\"\n",
      "\n",
      "Originally published in Poetry, March 18, 1887. Reprinted with the permission of Houghton Mifflin Company.     Copyright  1933, 1954 by SIR PHILIP SIDNEY.      Reprinted with the permission of Houghton Mifflin Company.     Copyright  1993 by SIR PHILIP SIDNEY.     Reprinted with the permission of Houghton Mifflin Company.     Copyright  1994 by SIR PHILIP SIDNEY.     Reprinted with the permission of Houghton Mifflin Company.     Copyright  1994 by SIR PHILIP SIDNEY.     Reprinted with the permission of Houghton M\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bdaa8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "Hench hath no hand,\r\n",
      "What skill can so strong a thing excel\r\n",
      "A horse to run upon a cart?\r\n",
      "                                                                                                                                                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad2bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "HENRY VIII, KING OF ENGLAND: My Wife. from Collected Poems, edited by Eusebius of Poitiers. Copyright  1966 by The Estate of Henry VIII, King of England. Reprinted with the permission of Alfred A. Knopf, an imprint of the Knopf Doubleday Publishing Group, a division of Random House LLC. All rights reserved.                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af46fc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a Renaissance Love poem written by HENRY VIII, KING OF ENGLAND called \"My Wife\"\n",
      "\n",
      "Envy and jealousy made my hair grow.\r\n",
      "Revolting my thoughts, and the mind of me black,\r\n",
      "Those were the things which made me so poor:\r\n",
      "A small fortune, which might not be:\r\n",
      "And had I not a lady of surpassing beauty,\r\n",
      "And yet spent the love of her, and been borne,\r\n",
      "Then did the love of her still rage,\r\n",
      "And I, whom I had so much worth,\r\n",
      "Had so little time to envy, and so little time to hate.\r\n",
      "By my love I sinned, and made my sin now found\r\n",
      "The cause of my amiss, that it made me angry.\r\n",
      "And the most grievous thing is, that I sinned:\r\n",
      "I did sin in love, which she spake:\r\n",
      "But my love was not love:\r\n",
      "And I sinned, that she spake;\r\n",
      "And sinned, that she spake;\r\n",
      "And sinned, in love which she did.\r\n",
      "The good that I sinned, and the good that I said,\r\n",
      "Was one, and it is not my own.\r\n",
      "Had I not no loves but her,\r\n",
      "Had\n"
     ]
    }
   ],
   "source": [
    "print(sample_model(\"HENRY VIII, KING OF ENGLAND\", \"My Wife\", \"Renaissance\", \"Love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edeee59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
